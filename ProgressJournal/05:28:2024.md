May 28th 2024

# Summary of Progress
In the past two weeks I have attempted the following:

1. Hand tune the $A$ and $B$ matrices of so that, in conjunction with the $C$ and $D$ matrices from the synthetic diagnostics, the dynamics of $x$ match experimental data while also matching the SOLPS steady-state conditions
2. Auto-tune the $A$ and $B$ matrices with MATLAB's `ssest` so that, in conjunction with the $C$ and $D$ matrices from the synthetic diagnostics, the dynamics of $x$ match experimental data -- does not abide by SOLPS constraints.
3. Try a smaller window -- so that it is computationally tractable -- over which to optimize the $A$ and $B$ matrices using a constrained least-sqaures method.
4. Looked into applying Jesse's divertor diffusion dynamics. Don't understand it yet.

**N.B. Linear Kalman Filter perfectly fuses sensor information when allowing for negative states**

## Details

### General notes on a discrete, linear divertor model

- **$A$ and $B$ should be positive to result in a positive $x$** -- i.e., no negative pressures or densities. The one caveat to this are relatively small enough negative values in $A$ so as to not create an outsized negative effect on $x$.
- **$A$ and $B$ should result in steady-state dynamics which align with SOLPS.** If they didn't, then real steady-state conditions (in $u$ and $x$) would not align with the static mapping, $C$ and $D$, from SOLPS.

### 1. Hand-tuning $A$ and $B$

Given the above requirements I tried to hand tune $A$ and $B$. I tried with a diagonal $B$ and a lower traigular $B$ with an accompnaying diagonal $A$, basing my choices on the model output I saw. Neither worked particularly well.

Here is an example where $B$ depends on the steady-state condition...

```
A11 = 0.9;
A22 = 0.9;
B11 = 0.1634*(1-A11);
B22 = 0.057679*(1-A22);
B21 = 0.016147*(1-A22);
A = [A11 0; 0 A22];
B = [B11 0 0 0; B21 B22 0 0];
C = [0.016308, 2.5134; 1.2834,  5.1023];
D = [0 0 FIR_intercept 0; 0 0 0 BOLO_intercept];
```

$`\begin{align}
A &= \begin{bmatrix}
    0.9 & 0 \\
    0 & 0.9
\end{bmatrix}\\
B &= \begin{bmatrix} 
    0.0163 & 0 & 0 & 0 & 0\\
    0.0016 & 0.0058 & 0 & 0 & 0
\end{bmatrix}\\
C &= \begin{bmatrix}
    0.0163 & 2.5134 \\
    1.2834 & 5.1023
\end{bmatrix}\\
D &= \begin{bmatrix}
    0 & 0 & 0.3227 & 0 \\
    0 & 0 & 0 & 1.8556
\end{bmatrix}
\end{align}`$

### 2. Auto-tuning $A$ and $B$

This did not yield particularly good results either. Additionally, `ssest` does not allow you to restrict the solution of $A$ relative to $B$ -- i.e., what is needed to satisfy the steady-state condition.

### 3. Smaller window for constrained least-squares

This did not yield particularly good results either. Performing least-squares on a window larger than 50 samples starts to be extremely slow on my PC. 50 out of the experiments 43,000 is barely a millisecond and doesn't give good results.

### 4. Looked into Jesse's diffusion model  

Two things I don't understand about it:
- How to approximate the non-rational transfer function with Chebyshev collocation
- How to fuse this model with the output mapping from SOLPS and the steady-state condition

## Next Steps

### Linear Kalman Filter (options)
1. Try to implement more complicated dynamics from Jesse's paper and perform point 1 (above) to "marry" the SOLPS output and steady-state to experimental data.

### Nonlinear Kalman Filter (options)
1. Try nonlinear fits for the static mapping from SOLPS. It seems like the output mapping could be the problem because the state dynamics $A$ and $B$ are well restricted by the steady-state condition.

### Other
- Make a third output corresponding to the location of the $y_{CIII}$ front.
- Still need to make plots of `qperp` (total perpendicular heat flux) and `fhix` (poloidal ion energy flux), but need MPCDF access via IPP!! Or ask Gijs nicely again.

### Continue with the other steps from [EndMarchCheckpoint](EndMarchCheckpoint.md):

1. Making more SynthDiag mappings $`\rightarrow y_{CIII}`$ map

2. <s> Making fake state dynamics with the steady-state response from SOLPS-ITER sims </s>

3. <s> Implementing a (linear) Kalman Filter </s> 

## Bigger Picture
### - $f(\bar{p}_0, \bar{n}_N)$ $\rightarrow$
### - Using $f(\bar{p}_0, \bar{n}_N)$ part of the Kalman filter update step becomes $K(y - f(\bar{p}_0, \bar{n}_N))$ where $y$ are the real sensor measurements and $K$ comes from (among other things) the process noise as defined by the RMSE of the fit on $f(\bar{p}_0, \bar{n}_N)$ $\rightarrow$

### - Create Best Guess Transfer Function (BGTF) for the state model with the steady-state being derived from linear fit on input output of sims.

### - Validating/testing both Kalman Filter and $f(\bar{p}_0, \bar{n}_N)$ comes down to using experimental data and BGTF (and eventually the FRF system identification of TCV exhaust) to update the state (i.e., the "State Model" block) in the loop with the Kalman Filter and checking that the of the KF residual has constant variance and zero mean. --> using $f(\bar{p}_0, \bar{n}_Z)$ the kalman filter residual becomes $K(y - f(p_0, n_Z))$ where $y$ are the real sensor measurements 
